{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c7c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37b9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.char_tokenizer import CharTokenizer, CharTokenizerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d1a04",
   "metadata": {},
   "source": [
    "# Testing Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "033abfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: {'<BOS>': 0, '<EOS>': 1, ' ': 2, 'd': 3, 'e': 4, 'h': 5, 'i': 6, 'l': 7, 'o': 8, 'r': 9, 'w': 10}\n",
      "Vocab size: 11\n"
     ]
    }
   ],
   "source": [
    "# small dummy text\n",
    "corpus = \"hello world hi\"\n",
    "\n",
    "# build tokenizer\n",
    "tok = CharTokenizer(corpus, config=CharTokenizerConfig(add_bos=True, add_eos=True))\n",
    "\n",
    "print(\"Vocab:\", tok.stoi)\n",
    "print(\"Vocab size:\", tok.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb73e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [0, 5, 6, 1]\n"
     ]
    }
   ],
   "source": [
    "# encode a sample\n",
    "sample = \"hi\"\n",
    "ids = tok.encode(sample)\n",
    "print(\"Encoded:\", ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b72998a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded: hi\n"
     ]
    }
   ],
   "source": [
    "# decode it back\n",
    "decoded = tok.decode(ids)\n",
    "print(\"Decoded:\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e321724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encode: [0, 5, 6, 1]\n",
      "Loaded decode: hi\n"
     ]
    }
   ],
   "source": [
    "# test save/load\n",
    "tok.save(\"artifacts/char_tok.json\")\n",
    "loaded = CharTokenizer.load(\"artifacts/char_tok.json\")\n",
    "\n",
    "print(\"Loaded encode:\", loaded.encode(sample))\n",
    "print(\"Loaded decode:\", loaded.decode(loaded.encode(sample)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ddd3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdb545",
   "metadata": {},
   "source": [
    "# Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31963af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.dataset import CharDataset\n",
    "from src.char_tokenizer import CharTokenizer\n",
    "\n",
    "root = Path(\".\")\n",
    "\n",
    "# 1) Load preprocessed data\n",
    "train_ids = torch.load(root / \"data\" / \"train_ids.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638d39c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Make a small dataset\n",
    "block_size = 8  # tiny just for inspection\n",
    "train_ds = CharDataset(train_ids, block_size=block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87132fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 1003845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 1003854)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Dataset length:\", len(train_ds)), len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1177acca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([8])\n",
      "y shape: torch.Size([8])\n",
      "x ids: [20, 49, 58, 59, 60, 3, 17, 49]\n",
      "y ids: [49, 58, 59, 60, 3, 17, 49, 60]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) Look at a single sample\n",
    "x, y = train_ds[0]\n",
    "print(\"x shape:\", x.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"x ids:\", x.tolist())\n",
    "print(\"y ids:\", y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9f10bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x text: First Ci\n",
      "y text: irst Cit\n"
     ]
    }
   ],
   "source": [
    "# 4) Decode to human-readable text\n",
    "tok = CharTokenizer.load(root / \"data\" / \"char_tokenizer.json\")\n",
    "print(\"x text:\", tok.decode(x.tolist()))\n",
    "print(\"y text:\", tok.decode(y.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "324930e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x shape: torch.Size([4, 8])\n",
      "Batch y shape: torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "# 5) Wrap in a DataLoader to see batching\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "\n",
    "batch_x, batch_y = next(iter(train_loader))\n",
    "print(\"Batch x shape:\", batch_x.shape)  # [batch, block_size]\n",
    "print(\"Batch y shape:\", batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "362969c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[48, 45, 58,  3, 56, 41, 52, 45],\n",
       "        [12,  2, 18, 55, 59, 60,  3, 60],\n",
       "        [45,  3, 54, 55,  3, 47, 58, 41],\n",
       "        [ 2, 17, 26, 23, 20, 20, 29, 32]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b43aa",
   "metadata": {},
   "source": [
    "# Testing Embedding Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e735f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.embeddings import GPTEmbedding\n",
    "from src.char_tokenizer import CharTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea1b4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer to get vocab_size\n",
    "tok = CharTokenizer.load(\"data/char_tokenizer.json\")\n",
    "vocab_size = tok.vocab_size\n",
    "\n",
    "\n",
    "# ðŸ”§ Recommended tiny config\n",
    "d_model = 128      # embedding / hidden size\n",
    "block_size = 128   # max context length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be6fb0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = GPTEmbedding(vocab_size=vocab_size,\n",
    "                     d_model=d_model,\n",
    "                     block_size=block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202cbbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : torch.Size([4, 128])\n",
      "Output shape: torch.Size([4, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Fake batch of token IDs just to test shapes\n",
    "batch_size = 4\n",
    "idx = torch.randint(0, vocab_size, (batch_size, block_size))  # [4, 128] - every element is a random integer between 0 and vocab_sizeâˆ’1, size is (4, 128)\n",
    "\n",
    "out = embed(idx)\n",
    "print(\"Input shape :\", idx.shape)   # torch.Size([4, 128])\n",
    "print(\"Output shape:\", out.shape)   # torch.Size([4, 128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb1e6c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490d6d16",
   "metadata": {},
   "source": [
    "# Testing Single head Attention block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43bf8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.attention import SingleHeadSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c8cfa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Hyperparameters\n",
    "# -------------------------\n",
    "batch_size = 2\n",
    "block_size = 5     # sequence length T\n",
    "d_model = 8        # embedding dimension\n",
    "d_head = 4         # attention head size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e767aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 5, 8])\n",
      "Output shape: torch.Size([2, 5, 4])\n",
      "tensor([[[-0.8871,  0.1435, -0.5848, -0.2220],\n",
      "         [-0.9292,  0.3800,  0.1793,  0.1037],\n",
      "         [-0.3648,  0.1516,  0.2950,  0.2457],\n",
      "         [-0.0495,  0.1000,  0.1602,  0.1275],\n",
      "         [ 0.0432, -0.0264, -0.2434,  0.0873]],\n",
      "\n",
      "        [[-0.7209, -0.0144,  0.1006,  0.8175],\n",
      "         [-0.3836, -0.0228, -0.6610,  0.6331],\n",
      "         [-0.1534, -0.1081, -0.5483,  0.6056],\n",
      "         [ 0.3325, -0.4727, -0.4010,  0.2374],\n",
      "         [-0.0347, -0.1647, -0.1051,  0.1884]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Create random input\n",
    "# -------------------------\n",
    "x = torch.randn(batch_size, block_size, d_model)  # [B, T, d_model]\n",
    "print(\"Input shape:\", x.shape)\n",
    "\n",
    "# -------------------------\n",
    "# Create attention module\n",
    "# -------------------------\n",
    "att = SingleHeadSelfAttention(\n",
    "    d_model=d_model,\n",
    "    d_head=d_head,\n",
    "    block_size=block_size\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Forward pass\n",
    "# -------------------------\n",
    "out = att(x)\n",
    "\n",
    "print(\"Output shape:\", out.shape)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7263ace7",
   "metadata": {},
   "source": [
    "# Testing entire transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c0264b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.block import TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77a824e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 5, 16])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Hyperparameters\n",
    "# -------------------------\n",
    "batch_size = 2\n",
    "block_size = 5      # sequence length T\n",
    "d_model = 16        # embedding size\n",
    "d_head = 8          # attention head size\n",
    "\n",
    "# -------------------------\n",
    "# Fake input: embeddings\n",
    "# -------------------------\n",
    "x = torch.randn(batch_size, block_size, d_model)\n",
    "print(\"Input shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "929f8c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 5, 16])\n",
      "tensor([[[-1.2179,  0.2314, -0.4609, -2.1366, -1.6178, -1.2819, -0.4578,\n",
      "           2.0654,  0.0117,  0.0976, -0.0517, -0.4331, -1.6662, -0.1376,\n",
      "           2.3905, -1.5338],\n",
      "         [ 0.1174,  0.2518, -1.8656, -0.8964, -1.3390, -0.0432,  2.8794,\n",
      "           1.4301,  0.1454, -0.4416,  1.0007, -0.1694, -0.8234,  0.8987,\n",
      "          -0.2490, -1.8497]]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Create one Transformer block\n",
    "# -------------------------\n",
    "block = TransformerBlock(\n",
    "    d_model=d_model,\n",
    "    d_head=d_head,\n",
    "    block_size=block_size,\n",
    "    mlp_hidden_mult=4,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Forward pass\n",
    "# -------------------------\n",
    "out = block(x)\n",
    "\n",
    "print(\"Output shape:\", out.shape)\n",
    "print(out[:1, :2])  # print first batch, first 2 tokens for a quick look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf68547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
